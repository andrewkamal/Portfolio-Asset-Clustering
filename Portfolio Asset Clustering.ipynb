{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c5efbc",
   "metadata": {},
   "source": [
    "# Portfolio Asset Clustering Project (Canary Group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc97cb3e",
   "metadata": {},
   "source": [
    "## Dataset Preparation and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e531cdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Excel...\n",
      "Loaded 249,024 rows for 500 stocks\n",
      "Date range: 2023-12-04 00:00:00 to 2025-11-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Loading data from Excel...\")\n",
    "# Read the Excel file created by R\n",
    "df = pd.read_excel('sp500_stock_data.xlsx', sheet_name='Stock_Data')\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows for {df['Ticker'].nunique()} stocks\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "\n",
    "# Convert Date to datetime if not already\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort by ticker and date\n",
    "df = df.sort_values(['Ticker', 'Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a33f71",
   "metadata": {},
   "source": [
    "### Feature calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66a35c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing A... ✓ 61 features\n",
      "Processing AAPL... ✓ 60 features\n",
      "Processing ABBV... ✓ 60 features\n",
      "Processing ABNB... ✓ 61 features\n",
      "Processing ABT... ✓ 61 features\n",
      "Processing ACGL... ✓ 60 features\n",
      "Processing ACN... ✓ 61 features\n",
      "Processing ADBE... ✓ 61 features\n",
      "Processing ADI... ✓ 61 features\n",
      "Processing ADM... ✓ 60 features\n",
      "Processing ADP... ✓ 61 features\n",
      "Processing ADSK... ✓ 60 features\n",
      "Processing AEE... ✓ 61 features\n",
      "Processing AEP... ✓ 60 features\n",
      "Processing AES... ✓ 61 features\n",
      "Processing AFL... ✓ 61 features\n",
      "Processing AIG... ✓ 61 features\n",
      "Processing AIZ... ✓ 61 features\n",
      "Processing AJG... ✓ 60 features\n",
      "Processing AKAM... ✓ 61 features\n",
      "Processing ALB... ✓ 61 features\n",
      "Processing ALGN... ✓ 61 features\n",
      "Processing ALL... ✓ 61 features\n",
      "Processing ALLE... ✓ 61 features\n",
      "Processing AMAT... ✓ 61 features\n",
      "Processing AMCR... ✓ 61 features\n",
      "Processing AMD... ✓ 61 features\n",
      "Processing AME... ✓ 61 features\n",
      "Processing AMGN... ✓ 61 features\n",
      "Processing AMP... ✓ 61 features\n",
      "Processing AMT... ✓ 60 features\n",
      "Processing AMZN... ✓ 61 features\n",
      "Processing ANET... ✓ 61 features\n",
      "Processing AON... ✓ 60 features\n",
      "Processing AOS... ✓ 61 features\n",
      "Processing APA... ✓ 61 features\n",
      "Processing APD... ✓ 60 features\n",
      "Processing APH... ✓ 61 features\n",
      "Processing APO... ✓ 60 features\n",
      "Processing APP... ✓ 60 features\n",
      "Processing APTV... ✓ 61 features\n",
      "Processing ARE... ✓ 60 features\n",
      "Processing ATO... ✓ 60 features\n",
      "Processing AVB... ✓ 60 features\n",
      "Processing AVGO... ✓ 61 features\n",
      "Processing AVY... ✓ 61 features\n",
      "Processing AWK... ✓ 60 features\n",
      "Processing AXON... ✓ 60 features\n",
      "Processing AXP... ✓ 61 features\n",
      "Processing AZO... ✓ 60 features\n",
      "Processing BA... ✓ 60 features\n",
      "Processing BAC... ✓ 60 features\n",
      "Processing BALL... ✓ 61 features\n",
      "Processing BAX... ✓ 61 features\n",
      "Processing BBY... ✓ 61 features\n",
      "Processing BDX... ✓ 61 features\n",
      "Processing BEN... ✓ 61 features\n",
      "Processing BF-B... ✓ 61 features\n",
      "Processing BG... ✓ 60 features\n",
      "Processing BIIB... ✓ 61 features\n",
      "Processing BK... ✓ 61 features\n",
      "Processing BKNG... ✓ 61 features\n",
      "Processing BKR... ✓ 60 features\n",
      "Processing BLDR... ✓ 61 features\n",
      "Processing BLK... ✓ 61 features\n",
      "Processing BMY... ✓ 61 features\n",
      "Processing BR... ✓ 61 features\n",
      "Processing BRK-B... ✓ 60 features\n",
      "Processing BRO... ✓ 61 features\n",
      "Processing BSX... ✓ 61 features\n",
      "Processing BX... ✓ 61 features\n",
      "Processing BXP... ✓ 60 features\n",
      "Processing C... ✓ 60 features\n",
      "Processing CAG... ✓ 61 features\n",
      "Processing CAH... ✓ 60 features\n",
      "Processing CARR... ✓ 60 features\n",
      "Processing CAT... ✓ 60 features\n",
      "Processing CB... ✓ 61 features\n",
      "Processing CBOE... ✓ 61 features\n",
      "Processing CBRE... ✓ 60 features\n",
      "Processing CCI... ✓ 60 features\n",
      "Processing CCL... ✓ 61 features\n",
      "Processing CDNS... ✓ 61 features\n",
      "Processing CDW... ✓ 61 features\n",
      "Processing CEG... ✓ 61 features\n",
      "Processing CF... ✓ 60 features\n",
      "Processing CFG... ✓ 61 features\n",
      "Processing CHD... ✓ 61 features\n",
      "Processing CHRW... ✓ 61 features\n",
      "Processing CHTR... ✓ 60 features\n",
      "Processing CI... ✓ 60 features\n",
      "Processing CINF... ✓ 60 features\n",
      "Processing CL... ✓ 61 features\n",
      "Processing CLX... ✓ 61 features\n",
      "Processing CMCSA... ✓ 61 features\n",
      "Processing CME... ✓ 61 features\n",
      "Processing CMG... ✓ 61 features\n",
      "Processing CMI... ✓ 61 features\n",
      "Processing CMS... ✓ 61 features\n",
      "Processing CNC... ✓ 61 features\n",
      "Processing CNP... ✓ 61 features\n",
      "Processing COF... ✓ 61 features\n",
      "Processing COIN... ✓ 61 features\n",
      "Processing COO... ✓ 61 features\n",
      "Processing COP... ✓ 61 features\n",
      "Processing COR... ✓ 60 features\n",
      "Processing COST... ✓ 60 features\n",
      "Processing CPAY... ✓ 61 features\n",
      "Processing CPB... ✓ 61 features\n",
      "Processing CPRT... ✓ 60 features\n",
      "Processing CPT... ✓ 60 features\n",
      "Processing CRL... ✓ 61 features\n",
      "Processing CRM... ✓ 61 features\n",
      "Processing CRWD... ✓ 60 features\n",
      "Processing CSCO... ✓ 61 features\n",
      "Processing CSGP... ✓ 61 features\n",
      "Processing CSX... ✓ 61 features\n",
      "Processing CTAS... ✓ 61 features\n",
      "Processing CTRA... ✓ 60 features\n",
      "Processing CTSH... ✓ 61 features\n",
      "Processing CTVA... ✓ 61 features\n",
      "Processing CVS... ✓ 60 features\n",
      "Processing CVX... ✓ 60 features\n",
      "Processing D... ✓ 61 features\n",
      "Processing DAL... ✓ 61 features\n",
      "Processing DASH... ✓ 61 features\n",
      "Processing DAY... ✓ 61 features\n",
      "Processing DD... ✓ 60 features\n",
      "Processing DDOG... ✓ 60 features\n",
      "Processing DE... ✓ 61 features\n",
      "Processing DECK... ✓ 61 features\n",
      "Processing DELL... ✓ 60 features\n",
      "Processing DG... ✓ 61 features\n",
      "Processing DGX... ✓ 61 features\n",
      "Processing DHI... ✓ 61 features\n",
      "Processing DHR... ✓ 61 features\n",
      "Processing DIS... ✓ 61 features\n",
      "Processing DLR... ✓ 61 features\n",
      "Processing DLTR... ✓ 61 features\n",
      "Processing DOC... ✓ 61 features\n",
      "Processing DOV... ✓ 61 features\n",
      "Processing DOW... ✓ 61 features\n",
      "Processing DPZ... ✓ 61 features\n",
      "Processing DRI... ✓ 61 features\n",
      "Processing DTE... ✓ 60 features\n",
      "Processing DUK... ✓ 61 features\n",
      "Processing DVA... ✓ 61 features\n",
      "Processing DVN... ✓ 60 features\n",
      "Processing DXCM... ✓ 61 features\n",
      "Processing EA... ✓ 60 features\n",
      "Processing EBAY... ✓ 61 features\n",
      "Processing ECL... ✓ 61 features\n",
      "Processing ED... ✓ 60 features\n",
      "Processing EFX... ✓ 61 features\n",
      "Processing EG... ✓ 61 features\n",
      "Processing EIX... ✓ 60 features\n",
      "Processing EL... ✓ 61 features\n",
      "Processing ELV... ✓ 61 features\n",
      "Processing EME... ✓ 61 features\n",
      "Processing EMR... ✓ 61 features\n",
      "Processing EOG... ✓ 61 features\n",
      "Processing EPAM... ✓ 60 features\n",
      "Processing EQIX... ✓ 61 features\n",
      "Processing EQR... ✓ 61 features\n",
      "Processing EQT... ✓ 61 features\n",
      "Processing ERIE... ✓ 60 features\n",
      "Processing ES... ✓ 61 features\n",
      "Processing ESS... ✓ 60 features\n",
      "Processing ETN... ✓ 61 features\n",
      "Processing ETR... ✓ 61 features\n",
      "Processing EVRG... ✓ 60 features\n",
      "Processing EW... ✓ 61 features\n",
      "Processing EXC... ✓ 61 features\n",
      "Processing EXE... ✓ 60 features\n",
      "Processing EXPD... ✓ 61 features\n",
      "Processing EXPE... ✓ 61 features\n",
      "Processing EXR... ✓ 61 features\n",
      "Processing F... ✓ 61 features\n",
      "Processing FANG... ✓ 61 features\n",
      "Processing FAST... ✓ 60 features\n",
      "Processing FCX... ✓ 61 features\n",
      "Processing FDS... ✓ 60 features\n",
      "Processing FDX... ✓ 61 features\n",
      "Processing FE... ✓ 60 features\n",
      "Processing FFIV... ✓ 60 features\n",
      "Processing FICO... ✓ 60 features\n",
      "Processing FIS... ✓ 61 features\n",
      "Processing FISV... ✓ 60 features\n",
      "Processing FITB... ✓ 60 features\n",
      "Processing FOX... ✓ 61 features\n",
      "Processing FOXA... ✓ 61 features\n",
      "Processing FRT... ✓ 61 features\n",
      "Processing FSLR... ✓ 61 features\n",
      "Processing FTNT... ✓ 61 features\n",
      "Processing FTV... ✓ 61 features\n",
      "Processing GD... ✓ 60 features\n",
      "Processing GDDY... ✓ 61 features\n",
      "Processing GE... ✓ 61 features\n",
      "Processing GEHC... ✓ 61 features\n",
      "Processing GEN... ✓ 60 features\n",
      "Processing GEV... ✓ 61 features\n",
      "Processing GILD... ✓ 61 features\n",
      "Processing GIS... ✓ 61 features\n",
      "Processing GL... ✓ 61 features\n",
      "Processing GLW... ✓ 61 features\n",
      "Processing GM... ✓ 61 features\n",
      "Processing GNRC... ✓ 60 features\n",
      "Processing GOOG... ✓ 61 features\n",
      "Processing GOOGL... ✓ 61 features\n",
      "Processing GPC... ✓ 61 features\n",
      "Processing GPN... ✓ 61 features\n",
      "Processing GRMN... ✓ 61 features\n",
      "Processing GS... ✓ 60 features\n",
      "Processing GWW... ✓ 61 features\n",
      "Processing HAL... ✓ 60 features\n",
      "Processing HAS... ✓ 61 features\n",
      "Processing HBAN... ✓ 60 features\n",
      "Processing HCA... ✓ 61 features\n",
      "Processing HD... ✓ 61 features\n",
      "Processing HIG... ✓ 61 features\n",
      "Processing HII... ✓ 61 features\n",
      "Processing HLT... ✓ 61 features\n",
      "Processing HOLX... ✓ 60 features\n",
      "Processing HON... ✓ 61 features\n",
      "Processing HOOD... ✓ 61 features\n",
      "Processing HPE... ✓ 61 features\n",
      "Processing HPQ... ✓ 61 features\n",
      "Processing HRL... ✓ 61 features\n",
      "Processing HSIC... ✓ 60 features\n",
      "Processing HST... ✓ 61 features\n",
      "Processing HSY... ✓ 61 features\n",
      "Processing HUBB... ✓ 61 features\n",
      "Processing HUM... ✓ 60 features\n",
      "Processing HWM... ✓ 61 features\n",
      "Processing IBKR... ✓ 61 features\n",
      "Processing IBM... ✓ 61 features\n",
      "Processing ICE... ✓ 60 features\n",
      "Processing IDXX... ✓ 61 features\n",
      "Processing IEX... ✓ 61 features\n",
      "Processing IFF... ✓ 61 features\n",
      "Processing INCY... ✓ 60 features\n",
      "Processing INTC... ✓ 61 features\n",
      "Processing INTU... ✓ 61 features\n",
      "Processing INVH... ✓ 61 features\n",
      "Processing IP... ✓ 60 features\n",
      "Processing IQV... ✓ 61 features\n",
      "Processing IR... ✓ 61 features\n",
      "Processing IRM... ✓ 60 features\n",
      "Processing ISRG... ✓ 61 features\n",
      "Processing IT... ✓ 61 features\n",
      "Processing ITW... ✓ 61 features\n",
      "Processing IVZ... ✓ 61 features\n",
      "Processing J... ✓ 60 features\n",
      "Processing JBHT... ✓ 61 features\n",
      "Processing JBL... ✓ 61 features\n",
      "Processing JCI... ✓ 60 features\n",
      "Processing JKHY... ✓ 60 features\n",
      "Processing JNJ... ✓ 61 features\n",
      "Processing JPM... ✓ 61 features\n",
      "Processing K... ✓ 61 features\n",
      "Processing KDP... ✓ 60 features\n",
      "Processing KEY... ✓ 61 features\n",
      "Processing KEYS... ✓ 60 features\n",
      "Processing KHC... ✓ 61 features\n",
      "Processing KIM... ✓ 61 features\n",
      "Processing KKR... ✓ 61 features\n",
      "Processing KLAC... ✓ 61 features\n",
      "Processing KMB... ✓ 60 features\n",
      "Processing KMI... ✓ 60 features\n",
      "Processing KO... ✓ 61 features\n",
      "Processing KR... ✓ 61 features\n",
      "Processing KVUE... ✓ 61 features\n",
      "Processing L... ✓ 61 features\n",
      "Processing LDOS... ✓ 60 features\n",
      "Processing LEN... ✓ 61 features\n",
      "Processing LH... ✓ 61 features\n",
      "Processing LHX... ✓ 61 features\n",
      "Processing LII... ✓ 61 features\n",
      "Processing LIN... ✓ 61 features\n",
      "Processing LKQ... ✓ 61 features\n",
      "Processing LLY... ✓ 60 features\n",
      "Processing LMT... ✓ 60 features\n",
      "Processing LNT... ✓ 61 features\n",
      "Processing LOW... ✓ 61 features\n",
      "Processing LRCX... ✓ 61 features\n",
      "Processing LULU... ✓ 61 features\n",
      "Processing LUV... ✓ 61 features\n",
      "Processing LVS... ✓ 61 features\n",
      "Processing LW... ✓ 60 features\n",
      "Processing LYB... ✓ 61 features\n",
      "Processing LYV... ✓ 61 features\n",
      "Processing MA... ✓ 61 features\n",
      "Processing MAA... ✓ 60 features\n",
      "Processing MAR... ✓ 61 features\n",
      "Processing MAS... ✓ 61 features\n",
      "Processing MCD... ✓ 61 features\n",
      "Processing MCHP... ✓ 61 features\n",
      "Processing MCK... ✓ 60 features\n",
      "Processing MCO... ✓ 61 features\n",
      "Processing MDLZ... ✓ 61 features\n",
      "Processing MDT... ✓ 61 features\n",
      "Processing MET... ✓ 61 features\n",
      "Processing META... ✓ 61 features\n",
      "Processing MGM... ✓ 61 features\n",
      "Processing MHK... ✓ 60 features\n",
      "Processing MKC... ✓ 61 features\n",
      "Processing MLM... ✓ 60 features\n",
      "Processing MMC... ✓ 60 features\n",
      "Processing MMM... ✓ 61 features\n",
      "Processing MNST... ✓ 61 features\n",
      "Processing MO... ✓ 60 features\n",
      "Processing MOH... ✓ 61 features\n",
      "Processing MOS... ✓ 61 features\n",
      "Processing MPC... ✓ 61 features\n",
      "Processing MPWR... ✓ 61 features\n",
      "Processing MRK... ✓ 60 features\n",
      "Processing MRNA... ✓ 60 features\n",
      "Processing MS... ✓ 60 features\n",
      "Processing MSCI... ✓ 61 features\n",
      "Processing MSFT... ✓ 61 features\n",
      "Processing MSI... ✓ 61 features\n",
      "Processing MTB... ✓ 61 features\n",
      "Processing MTCH... ✓ 61 features\n",
      "Processing MTD... ✓ 61 features\n",
      "Processing MU... ✓ 60 features\n",
      "Processing NCLH... ✓ 61 features\n",
      "Processing NDAQ... ✓ 61 features\n",
      "Processing NDSN... ✓ 60 features\n",
      "Processing NEE... ✓ 61 features\n",
      "Processing NEM... ✓ 61 features\n",
      "Processing NFLX... ✓ 61 features\n",
      "Processing NI... ✓ 61 features\n",
      "Processing NKE... ✓ 61 features\n",
      "Processing NOC... ✓ 61 features\n",
      "Processing NOW... ✓ 61 features\n",
      "Processing NRG... ✓ 61 features\n",
      "Processing NSC... ✓ 61 features\n",
      "Processing NTAP... ✓ 60 features\n",
      "Processing NTRS... ✓ 61 features\n",
      "Processing NUE... ✓ 61 features\n",
      "Processing NVDA... ✓ 61 features\n",
      "Processing NVR... ✓ 61 features\n",
      "Processing NWS... ✓ 60 features\n",
      "Processing NWSA... ✓ 61 features\n",
      "Processing NXPI... ✓ 61 features\n",
      "Processing O... ✓ 60 features\n",
      "Processing ODFL... ✓ 61 features\n",
      "Processing OKE... ✓ 60 features\n",
      "Processing OMC... ✓ 61 features\n",
      "Processing ON... ✓ 61 features\n",
      "Processing ORCL... ✓ 61 features\n",
      "Processing ORLY... ✓ 60 features\n",
      "Processing OTIS... ✓ 61 features\n",
      "Processing OXY... ✓ 61 features\n",
      "Processing PANW... ✓ 60 features\n",
      "Processing PAYC... ✓ 60 features\n",
      "Processing PAYX... ✓ 61 features\n",
      "Processing PCAR... ✓ 61 features\n",
      "Processing PCG... ✓ 60 features\n",
      "Processing PEG... ✓ 61 features\n",
      "Processing PEP... ✓ 61 features\n",
      "Processing PFE... ✓ 61 features\n",
      "Processing PFG... ✓ 61 features\n",
      "Processing PG... ✓ 61 features\n",
      "Processing PGR... ✓ 61 features\n",
      "Processing PH... ✓ 61 features\n",
      "Processing PHM... ✓ 61 features\n",
      "Processing PKG... ✓ 61 features\n",
      "Processing PLD... ✓ 61 features\n",
      "Processing PLTR... ✓ 61 features\n",
      "Processing PM... ✓ 61 features\n",
      "Processing PNC... ✓ 60 features\n",
      "Processing PNR... ✓ 61 features\n",
      "Processing PNW... ✓ 61 features\n",
      "Processing PODD... ✓ 61 features\n",
      "Processing POOL... ✓ 61 features\n",
      "Processing PPG... ✓ 61 features\n",
      "Processing PPL... ✓ 60 features\n",
      "Processing PRU... ✓ 60 features\n",
      "Processing PSA... ✓ 61 features\n",
      "Processing PSKY... ✓ 61 features\n",
      "Processing PSX... ✓ 60 features\n",
      "Processing PTC... ✓ 61 features\n",
      "Processing PWR... ✓ 61 features\n",
      "Processing PYPL... ✓ 61 features\n",
      "Processing QCOM... ✓ 61 features\n",
      "Processing RCL... ✓ 61 features\n",
      "Processing REG... ✓ 61 features\n",
      "Processing REGN... ✓ 61 features\n",
      "Processing RF... ✓ 60 features\n",
      "Processing RJF... ✓ 61 features\n",
      "Processing RL... ✓ 61 features\n",
      "Processing RMD... ✓ 61 features\n",
      "Processing ROK... ✓ 61 features\n",
      "Processing ROL... ✓ 61 features\n",
      "Processing ROP... ✓ 61 features\n",
      "Processing ROST... ✓ 61 features\n",
      "Processing RSG... ✓ 61 features\n",
      "Processing RTX... ✓ 61 features\n",
      "Processing RVTY... ✓ 61 features\n",
      "Processing SBAC... ✓ 61 features\n",
      "Processing SBUX... ✓ 61 features\n",
      "Processing SCHW... ✓ 60 features\n",
      "Processing SHW... ✓ 61 features\n",
      "Processing SJM... ✓ 61 features\n",
      "Processing SLB... ✓ 61 features\n",
      "Processing SMCI... ✓ 60 features\n",
      "Processing SNA... ✓ 61 features\n",
      "Processing SNPS... ✓ 61 features\n",
      "Processing SO... ✓ 61 features\n",
      "Processing SOLV... ✓ 60 features\n",
      "Processing SPG... ✓ 61 features\n",
      "Processing SPGI... ✓ 61 features\n",
      "Processing SRE... ✓ 61 features\n",
      "Processing STE... ✓ 61 features\n",
      "Processing STLD... ✓ 61 features\n",
      "Processing STT... ✓ 60 features\n",
      "Processing STX... ✓ 60 features\n",
      "Processing STZ... ✓ 61 features\n",
      "Processing SW... ✓ 61 features\n",
      "Processing SWK... ✓ 61 features\n",
      "Processing SWKS... ✓ 61 features\n",
      "Processing SYF... ✓ 61 features\n",
      "Processing SYK... ✓ 61 features\n",
      "Processing SYY... ✓ 61 features\n",
      "Processing T... ✓ 61 features\n",
      "Processing TAP... ✓ 61 features\n",
      "Processing TDG... ✓ 61 features\n",
      "Processing TDY... ✓ 61 features\n",
      "Processing TECH... ✓ 61 features\n",
      "Processing TEL... ✓ 61 features\n",
      "Processing TER... ✓ 61 features\n",
      "Processing TFC... ✓ 60 features\n",
      "Processing TGT... ✓ 61 features\n",
      "Processing TJX... ✓ 61 features\n",
      "Processing TKO... ✓ 61 features\n",
      "Processing TMO... ✓ 61 features\n",
      "Processing TMUS... ✓ 61 features\n",
      "Processing TPL... ✓ 60 features\n",
      "Processing TPR... ✓ 61 features\n",
      "Processing TRGP... ✓ 60 features\n",
      "Processing TRMB... ✓ 61 features\n",
      "Processing TROW... ✓ 61 features\n",
      "Processing TRV... ✓ 61 features\n",
      "Processing TSCO... ✓ 60 features\n",
      "Processing TSLA... ✓ 61 features\n",
      "Processing TSN... ✓ 61 features\n",
      "Processing TT... ✓ 61 features\n",
      "Processing TTD... ✓ 60 features\n",
      "Processing TTWO... ✓ 61 features\n",
      "Processing TXN... ✓ 61 features\n",
      "Processing TXT... ✓ 60 features\n",
      "Processing TYL... ✓ 61 features\n",
      "Processing UAL... ✓ 61 features\n",
      "Processing UBER... ✓ 61 features\n",
      "Processing UDR... ✓ 60 features\n",
      "Processing UHS... ✓ 60 features\n",
      "Processing ULTA... ✓ 61 features\n",
      "Processing UNH... ✓ 60 features\n",
      "Processing UNP... ✓ 61 features\n",
      "Processing UPS... ✓ 61 features\n",
      "Processing URI... ✓ 61 features\n",
      "Processing USB... ✓ 61 features\n",
      "Processing V... ✓ 61 features\n",
      "Processing VICI... ✓ 60 features\n",
      "Processing VLO... ✓ 60 features\n",
      "Processing VLTO... ✓ 61 features\n",
      "Processing VMC... ✓ 60 features\n",
      "Processing VRSK... ✓ 61 features\n",
      "Processing VRSN... ✓ 60 features\n",
      "Processing VRTX... ✓ 61 features\n",
      "Processing VST... ✓ 61 features\n",
      "Processing VTR... ✓ 61 features\n",
      "Processing VTRS... ✓ 61 features\n",
      "Processing VZ... ✓ 61 features\n",
      "Processing WAB... ✓ 61 features\n",
      "Processing WAT... ✓ 61 features\n",
      "Processing WBD... ✓ 60 features\n",
      "Processing WDAY... ✓ 61 features\n",
      "Processing WDC... ✓ 60 features\n",
      "Processing WEC... ✓ 61 features\n",
      "Processing WELL... ✓ 61 features\n",
      "Processing WFC... ✓ 60 features\n",
      "Processing WM... ✓ 61 features\n",
      "Processing WMB... ✓ 61 features\n",
      "Processing WMT... ✓ 61 features\n",
      "Processing WRB... ✓ 61 features\n",
      "Processing WSM... ✓ 61 features\n",
      "Processing WST... ✓ 61 features\n",
      "Processing WTW... ✓ 60 features\n",
      "Processing WY... ✓ 61 features\n",
      "Processing WYNN... ✓ 61 features\n",
      "Processing XEL... ✓ 60 features\n",
      "Processing XOM... ✓ 60 features\n",
      "Processing XYL... ✓ 61 features\n",
      "Processing XYZ... ✓ 61 features\n",
      "Processing YUM... ✓ 61 features\n",
      "Processing ZBH... ✓ 61 features\n",
      "Processing ZBRA... ✓ 61 features\n",
      "Processing ZTS... ✓ 61 features\n",
      "\n",
      "============================================================\n",
      "FEATURE EXTRACTION COMPLETE\n",
      "============================================================\n",
      "Total stocks: 500\n",
      "Total features: 61\n",
      "\n",
      "Feature columns:\n",
      "['ticker', 'sector', 'industry', 'company', 'daily_return_mean', 'daily_return_std', 'annualized_return', 'annualized_volatility', 'return_1m', 'return_3m', 'return_6m', 'return_1y', 'cumulative_return', 'downside_deviation', 'semi_variance', 'max_drawdown', 'var_95', 'var_99', 'cvar_95', 'cvar_99', 'sharpe_ratio', 'sortino_ratio', 'calmar_ratio', 'omega_ratio', 'sma_20', 'sma_50', 'sma_200', 'ema_12', 'ema_26', 'rsi', 'macd', 'macd_signal', 'bb_position', 'bb_width', 'momentum_10d', 'momentum_20d', 'volume_ratio', 'volume_trend', 'skewness', 'kurtosis', 'autocorr_lag1', 'autocorr_lag5', 'hurst_exponent', 'avg_volume', 'avg_dollar_volume', 'volume_volatility', 'amihud_illiquidity', 'roll_measure', 'tail_ratio', 'expected_shortfall', 'gain_to_pain', 'win_rate', 'max_daily_gain', 'max_daily_loss', 'latest_price', 'latest_volume', 'min_price', 'max_price', 'avg_price', 'price_range', 'price_range_pct']\n"
     ]
    }
   ],
   "source": [
    "# Feature calculation functions\n",
    "def calculate_returns_features(group):\n",
    "    \"\"\"Calculate return-based features\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    returns = group['Daily_Return'].dropna()\n",
    "    \n",
    "    if len(returns) < 30:\n",
    "        return pd.Series(features)\n",
    "    \n",
    "    # Basic return metrics\n",
    "    features['daily_return_mean'] = returns.mean()\n",
    "    features['daily_return_std'] = returns.std()\n",
    "    features['annualized_return'] = returns.mean() * 252\n",
    "    features['annualized_volatility'] = returns.std() * np.sqrt(252)\n",
    "    \n",
    "    # Period returns\n",
    "    if len(group) >= 21:\n",
    "        features['return_1m'] = (group['Close'].iloc[-1] / group['Close'].iloc[-21]) - 1\n",
    "    if len(group) >= 63:\n",
    "        features['return_3m'] = (group['Close'].iloc[-1] / group['Close'].iloc[-63]) - 1\n",
    "    if len(group) >= 126:\n",
    "        features['return_6m'] = (group['Close'].iloc[-1] / group['Close'].iloc[-126]) - 1\n",
    "    if len(group) >= 252:\n",
    "        features['return_1y'] = (group['Close'].iloc[-1] / group['Close'].iloc[-252]) - 1\n",
    "    \n",
    "    # Cumulative return\n",
    "    features['cumulative_return'] = (group['Close'].iloc[-1] / group['Close'].iloc[0]) - 1\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "def calculate_risk_features(group):\n",
    "    \"\"\"Calculate risk metrics\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    returns = group['Daily_Return'].dropna()\n",
    "    \n",
    "    if len(returns) < 30:\n",
    "        return pd.Series(features)\n",
    "    \n",
    "    # Downside metrics\n",
    "    negative_returns = returns[returns < 0]\n",
    "    features['downside_deviation'] = negative_returns.std() * np.sqrt(252)\n",
    "    features['semi_variance'] = negative_returns.var()\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    features['max_drawdown'] = drawdown.min()\n",
    "    \n",
    "    # VaR and CVaR\n",
    "    features['var_95'] = returns.quantile(0.05)\n",
    "    features['var_99'] = returns.quantile(0.01)\n",
    "    features['cvar_95'] = returns[returns <= features['var_95']].mean()\n",
    "    features['cvar_99'] = returns[returns <= features['var_99']].mean()\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "def calculate_risk_adjusted_features(group, risk_free_rate=0.04):\n",
    "    \"\"\"Calculate risk-adjusted metrics\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    returns = group['Daily_Return'].dropna()\n",
    "    \n",
    "    if len(returns) < 30:\n",
    "        return pd.Series(features)\n",
    "    \n",
    "    ann_return = returns.mean() * 252\n",
    "    ann_vol = returns.std() * np.sqrt(252)\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    if ann_vol > 0:\n",
    "        features['sharpe_ratio'] = (ann_return - risk_free_rate) / ann_vol\n",
    "    \n",
    "    # Sortino ratio\n",
    "    negative_returns = returns[returns < 0]\n",
    "    downside_std = negative_returns.std() * np.sqrt(252)\n",
    "    if downside_std > 0:\n",
    "        features['sortino_ratio'] = (ann_return - risk_free_rate) / downside_std\n",
    "    \n",
    "    # Calmar ratio\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    max_dd = drawdown.min()\n",
    "    if max_dd < 0:\n",
    "        features['calmar_ratio'] = ann_return / abs(max_dd)\n",
    "    \n",
    "    # Omega ratio\n",
    "    threshold = 0\n",
    "    excess_returns = returns - threshold\n",
    "    gains = excess_returns[excess_returns > 0].sum()\n",
    "    losses = -excess_returns[excess_returns < 0].sum()\n",
    "    if losses > 0:\n",
    "        features['omega_ratio'] = gains / losses\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "def calculate_technical_features(group):\n",
    "    \"\"\"Calculate technical indicators\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    close = group['Close']\n",
    "    \n",
    "    if len(close) < 50:\n",
    "        return pd.Series(features)\n",
    "    \n",
    "    # Moving averages\n",
    "    features['sma_20'] = close.rolling(window=20).mean().iloc[-1] / close.iloc[-1]\n",
    "    features['sma_50'] = close.rolling(window=50).mean().iloc[-1] / close.iloc[-1]\n",
    "    if len(close) >= 200:\n",
    "        features['sma_200'] = close.rolling(window=200).mean().iloc[-1] / close.iloc[-1]\n",
    "    \n",
    "    # EMA\n",
    "    features['ema_12'] = close.ewm(span=12).mean().iloc[-1] / close.iloc[-1]\n",
    "    features['ema_26'] = close.ewm(span=26).mean().iloc[-1] / close.iloc[-1]\n",
    "    \n",
    "    # RSI\n",
    "    delta = close.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    features['rsi'] = rsi.iloc[-1]\n",
    "    \n",
    "    # MACD\n",
    "    ema_12 = close.ewm(span=12).mean()\n",
    "    ema_26 = close.ewm(span=26).mean()\n",
    "    macd_line = ema_12 - ema_26\n",
    "    signal_line = macd_line.ewm(span=9).mean()\n",
    "    features['macd'] = macd_line.iloc[-1]\n",
    "    features['macd_signal'] = signal_line.iloc[-1]\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    sma = close.rolling(window=20).mean()\n",
    "    std = close.rolling(window=20).std()\n",
    "    upper_band = sma + (std * 2)\n",
    "    lower_band = sma - (std * 2)\n",
    "    current_price = close.iloc[-1]\n",
    "    features['bb_position'] = (current_price - lower_band.iloc[-1]) / (upper_band.iloc[-1] - lower_band.iloc[-1])\n",
    "    features['bb_width'] = (upper_band.iloc[-1] - lower_band.iloc[-1]) / close.iloc[-1]\n",
    "    \n",
    "    # Momentum\n",
    "    if len(close) >= 10:\n",
    "        features['momentum_10d'] = (close.iloc[-1] / close.iloc[-10]) - 1\n",
    "    if len(close) >= 20:\n",
    "        features['momentum_20d'] = (close.iloc[-1] / close.iloc[-20]) - 1\n",
    "    \n",
    "    # Volume indicators\n",
    "    volume = group['Volume']\n",
    "    features['volume_ratio'] = volume.iloc[-20:].mean() / volume.mean()\n",
    "    \n",
    "    # Volume trend\n",
    "    volumes = volume.iloc[-20:]\n",
    "    x = np.arange(len(volumes))\n",
    "    if len(volumes) > 0:\n",
    "        slope, _ = np.polyfit(x, volumes, 1)\n",
    "        features['volume_trend'] = slope / volumes.mean()\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "def calculate_statistical_features(group):\n",
    "    \"\"\"Calculate statistical features\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    returns = group['Daily_Return'].dropna()\n",
    "    \n",
    "    if len(returns) < 30:\n",
    "        return pd.Series(features)\n",
    "    \n",
    "    # Skewness and Kurtosis\n",
    "    features['skewness'] = stats.skew(returns)\n",
    "    features['kurtosis'] = stats.kurtosis(returns)\n",
    "    \n",
    "    # Autocorrelation\n",
    "    if len(returns) > 5:\n",
    "        features['autocorr_lag1'] = returns.autocorr(lag=1)\n",
    "        features['autocorr_lag5'] = returns.autocorr(lag=5)\n",
    "    \n",
    "    # Hurst exponent\n",
    "    try:\n",
    "        lags = range(2, 20)\n",
    "        tau = []\n",
    "        lagvec = []\n",
    "        \n",
    "        for lag in lags:\n",
    "            pp = np.array(returns[lag:])\n",
    "            pp1 = np.array(returns[:-lag])\n",
    "            tau.append(np.sqrt(np.std(np.subtract(pp, pp1))))\n",
    "            lagvec.append(lag)\n",
    "        \n",
    "        if len(tau) > 0:\n",
    "            poly = np.polyfit(np.log(lagvec), np.log(tau), 1)\n",
    "            features['hurst_exponent'] = poly[0] * 2.0\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "def calculate_liquidity_features(group):\n",
    "    \"\"\"Calculate liquidity metrics\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    if len(group) < 30:\n",
    "        return pd.Series(features)\n",
    "    \n",
    "    # Volume metrics\n",
    "    features['avg_volume'] = group['Volume'].mean()\n",
    "    features['avg_dollar_volume'] = (group['Close'] * group['Volume']).mean()\n",
    "    features['volume_volatility'] = group['Volume'].std() / group['Volume'].mean()\n",
    "    \n",
    "    # Amihud illiquidity ratio\n",
    "    returns = group['Daily_Return'].dropna()\n",
    "    dollar_volume = group['Close'] * group['Volume']\n",
    "    illiquidity = (returns.abs() / dollar_volume).replace([np.inf, -np.inf], np.nan).mean()\n",
    "    features['amihud_illiquidity'] = illiquidity * 1e6\n",
    "    \n",
    "    # Roll measure\n",
    "    try:\n",
    "        cov = returns.autocorr(lag=1) * returns.var()\n",
    "        if cov < 0:\n",
    "            features['roll_measure'] = 2 * np.sqrt(-cov)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "def calculate_tail_risk_features(group):\n",
    "    \"\"\"Calculate tail risk metrics\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    returns = group['Daily_Return'].dropna()\n",
    "    \n",
    "    if len(returns) < 100:\n",
    "        return pd.Series(features)\n",
    "    \n",
    "    # Tail ratio\n",
    "    right_tail = returns.quantile(0.95)\n",
    "    left_tail = returns.quantile(0.05)\n",
    "    if left_tail != 0:\n",
    "        features['tail_ratio'] = abs(right_tail / left_tail)\n",
    "    \n",
    "    # Expected shortfall\n",
    "    features['expected_shortfall'] = returns[returns <= returns.quantile(0.05)].mean()\n",
    "    \n",
    "    # Gain-to-pain ratio\n",
    "    gains = returns[returns > 0].sum()\n",
    "    pains = abs(returns[returns < 0].sum())\n",
    "    if pains > 0:\n",
    "        features['gain_to_pain'] = gains / pains\n",
    "    \n",
    "    # Win rate\n",
    "    features['win_rate'] = (returns > 0).sum() / len(returns)\n",
    "    \n",
    "    # Extreme values\n",
    "    features['max_daily_gain'] = returns.max()\n",
    "    features['max_daily_loss'] = returns.min()\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "def calculate_price_features(group):\n",
    "    \"\"\"Calculate price-based features\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Latest price info\n",
    "    features['latest_price'] = group['Close'].iloc[-1]\n",
    "    features['latest_volume'] = group['Volume'].iloc[-1]\n",
    "    \n",
    "    # Price statistics\n",
    "    features['min_price'] = group['Close'].min()\n",
    "    features['max_price'] = group['Close'].max()\n",
    "    features['avg_price'] = group['Close'].mean()\n",
    "    features['price_range'] = features['max_price'] - features['min_price']\n",
    "    features['price_range_pct'] = features['price_range'] / features['avg_price']\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "features_list = []\n",
    "\n",
    "for ticker, group in df.groupby('Ticker'):\n",
    "    print(f\"Processing {ticker}... \", end='')\n",
    "    \n",
    "    try:\n",
    "        features = {'ticker': ticker}\n",
    "        \n",
    "        # Get categorical features\n",
    "        features['sector'] = group['sector'].iloc[0] if 'sector' in group.columns else 'Unknown'\n",
    "        features['industry'] = group['industry'].iloc[0] if 'industry' in group.columns else 'Unknown'\n",
    "        features['company'] = group['company'].iloc[0] if 'company' in group.columns else 'Unknown'\n",
    "        \n",
    "        # Calculate all numeric features\n",
    "        features.update(calculate_returns_features(group).to_dict())\n",
    "        features.update(calculate_risk_features(group).to_dict())\n",
    "        features.update(calculate_risk_adjusted_features(group).to_dict())\n",
    "        features.update(calculate_technical_features(group).to_dict())\n",
    "        features.update(calculate_statistical_features(group).to_dict())\n",
    "        features.update(calculate_liquidity_features(group).to_dict())\n",
    "        features.update(calculate_tail_risk_features(group).to_dict())\n",
    "        features.update(calculate_price_features(group).to_dict())\n",
    "        \n",
    "        features_list.append(features)\n",
    "        print(f\"✓ {len(features)} features\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {e}\")\n",
    "\n",
    "# Create final features DataFrame\n",
    "features_df = pd.DataFrame(features_list)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FEATURE EXTRACTION COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total stocks: {len(features_df)}\")\n",
    "print(f\"Total features: {len(features_df.columns)}\")\n",
    "print(f\"\\nFeature columns:\")\n",
    "print(features_df.columns.tolist())\n",
    "\n",
    "\n",
    "# Save to CSV and Excel\n",
    "features_df.to_excel('sp500_features.xlsx', index=False)\n",
    "features_df.to_csv('sp500_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b18ff0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY STATISTICS\n",
      "============================================================\n",
      "\n",
      "Features by category:\n",
      "  Returns: 8\n",
      "  Risk: 13\n",
      "  Technical: 10\n",
      "  Statistical: 5\n",
      "  Liquidity: 7\n",
      "  Tail Risk: 4\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Show feature summary\n",
    "print(\"\\nFeatures by category:\")\n",
    "print(f\"  Returns: {len([c for c in features_df.columns if 'return' in c.lower()])}\")\n",
    "print(f\"  Risk: {len([c for c in features_df.columns if 'var' in c.lower() or 'vol' in c.lower() or 'drawdown' in c.lower()])}\")\n",
    "print(f\"  Technical: {len([c for c in features_df.columns if any(x in c.lower() for x in ['sma', 'ema', 'rsi', 'macd', 'bb'])])}\")\n",
    "print(f\"  Statistical: {len([c for c in features_df.columns if any(x in c.lower() for x in ['skew', 'kurt', 'autocorr', 'hurst'])])}\")\n",
    "print(f\"  Liquidity: {len([c for c in features_df.columns if 'volume' in c.lower() or 'liquidity' in c.lower()])}\")\n",
    "print(f\"  Tail Risk: {len([c for c in features_df.columns if any(x in c.lower() for x in ['tail', 'shortfall', 'gain_to_pain', 'win_rate'])])}\")\n",
    "print(f\"{'\\n'+'='*60+'\\n'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd410f8",
   "metadata": {},
   "source": [
    "### LOAD AND EXPLORE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12ab8f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Shape: (500, 61)\n",
      "Number of stocks: 500\n",
      "Number of features: 61\n",
      "\n",
      "Numerical features: 57\n",
      "Categorical features: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Missing Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Percentage (%)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "59c07bf8-f8c7-459a-8113-7400a1d823b2",
       "rows": [
        [
         "roll_measure",
         "134",
         "26.8"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roll_measure</th>\n",
       "      <td>134</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Count  Percentage (%)\n",
       "roll_measure            134            26.8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df = pd.read_csv('sp500_features.csv')\n",
    "\n",
    "print(f\"\\nDataset Shape: {stock_df.shape}\")\n",
    "print(f\"Number of stocks: {len(stock_df['ticker'].unique())}\")\n",
    "print(f\"Number of features: {len(stock_df.columns)}\")\n",
    "\n",
    "# Get categorical features\n",
    "categorical_cols = ['ticker', 'company', 'sector', 'industry']\n",
    "stock_df_categorical = stock_df[categorical_cols].copy()\n",
    "\n",
    "# Get numerical features\n",
    "numerical_cols = [col for col in stock_df.columns if col not in categorical_cols]\n",
    "stock_df_numerical = stock_df[numerical_cols].copy()\n",
    "\n",
    "print(f\"\\nNumerical features: {len(numerical_cols)}\")\n",
    "print(f\"Categorical features: {len(categorical_cols)}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_vals = stock_df.isnull().sum()\n",
    "missing_per = ((stock_df.isnull().sum() / len(stock_df)) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame({'Missing Count': missing_vals,'Percentage (%)': missing_per}) # Combine into a DataFrame for better visualization\n",
    "missing_df[missing_df['Missing Count'] > 0].sort_values(by='Missing Count', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
